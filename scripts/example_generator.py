

Imports="""
import os
import sys
import numpy as np
import mtuq.dataset.sac
import mtuq.greens_tensor.fk

from os.path import basename, join
from mtuq.grid_search import DCGridRandom
from mtuq.grid_search import grid_search_mpi
from mtuq.misfit.cap import misfit
from mtuq.process_data.cap import process_data
from mtuq.util.cap_util import trapezoid_rise_time, Trapezoid
from mtuq.util.plot import plot_waveforms
from mtuq.util.util import cross, root


"""


DocstringDC3Serial="""
if __name__=='__main__':
    #
    # Double-couple inversion example
    # 
    # Carries out grid search over 50,000 randomly chosen double-couple 
    # moment tensors
    #
    # USAGE
    #   python GridSearchDC3Serial.py
    #
    # A typical runtime is about 60 minutes. For faster results, try 
    # GridSearchDC3.py, which runs the same inversion in parallel rather than
    # serial
    #

"""


DocstringDC3="""
if __name__=='__main__':
    #
    # Double-couple inversion example
    # 
    # Carries out grid search over 50,000 randomly chosen double-couple 
    # moment tensors
    #
    # USAGE
    #   mpirun -n <NPROC> python GridSearchDC3.py
    #
    # If you are browsing the examples and would prefer a slightly simpler
    # starting point, see  examples/GridSearch.DoubleCouple3.Serial.py, 
    # which runs the exactly the same inversion, except in serial rather than 
    # in parallel
    #

"""


DocstringDC5="""
if __name__=='__main__':
    #
    # Double-couple inversion example
    # 
    # Carries out grid search over source orientation, magnitude and depth
    #
    # USAGE
    #   mpirun -n <NPROC> python GridSearchDC5.py
    #
    # If you are browsing the examples and would prefer a simpler
    # starting point, see  examples/GridSearch.DoubleCouple3.Serial.py
    #

"""


DocstringFMT5="""
if __name__=='__main__':
    #
    # Full moment tensor inversion example
    # 
    # Carries out grid search over all moment tensor parameters except
    # magnitude 
    #
    # USAGE
    #   mpirun -n <NPROC> python GridSearchFullMT.py
    #
    # If you are browsing the examples and would prefer a simpler
    # starting point, see  examples/GridSearch.DoubleCouple3.Serial.py


"""


DocstringBenchmarkCAPFK="""
if __name__=='__main__':
    #
    # Given a moment tensor, generates MTUQ synthetics and compares with
    # corresponding CAP/FK synthetics
    #
    # This script is similar to examples/GridSearch.DoubleCouple3.Serial.py,
    # except here we consider only a single grid point rather than an entire
    # grid, and here the final plot is a comparison of MTUQ and CAP/FK 
    # synthetics rather than a comparison of data and synthetics
    #
    # The CAP/FK synthetics used for the comparison were generated by the 
    # following commands
    #
    # explosion source:
    # cap.pl -H0.02 -P1/15/60 -p1 -S2/10/0 -T15/150 -D1/1/0.5 -C0.25/0.6667/0.025/0.0625 -Y1 -Zweight_test.dat -Mscak_34 -m4.3 -I1 -R0/0/1.1780972450961724/1.1780972450961724/90/90/0/0/90/90 20090407201255351
    #
    # double-couple source:
    # cap.pl -H0.02 -P1/15/60 -p1 -S2/10/0 -T15/150 -D1/1/0.5 -C0.25/0.6667/0.025/0.0625 -Y1 -Zweight_test.dat -Mscak_34 -m4.3 -I1 -R0/0/0/0/180/180/0.5/0.5/0/0 20090407201255351
    #
"""


DocstringIntegrationTest="""
if __name__=='__main__':
    #
    #
    # This script is similar to examples/GridSearch.DoubleCouple3.Serial.py,
    # except here we use a coarser grid, and at the end we assert the test
    # that the test result equals the expected result
    #
    # The compare against CAP/FK run the following command:
    # cap.pl ???

"""


PathsComments="""
    #
    # Here we specify the data used for the inversion. The event is an 
    # Mw~4 Alaska earthquake
    #
"""


PathsDefinitions="""
    path_data=    join(root(), 'tests/data/20090407201255351')
    path_weights= join(root(), 'tests/data/20090407201255351/weights.dat')
    # Fow now this path exists only in my personal environment.  Eventually, 
    # we need to include it in the repository or make it available for download
    path_greens=  join(os.getenv('CENTER1'), 'data/wf/FK_SYNTHETICS/scak')
    event_name = '20090407201255351'

"""


DataProcessingComments="""
    #
    # Body- and surface-wave data are processed separately and held separately 
    # in memory
    #
"""


DataProcessingDefinitions="""
    process_bw = process_data(
        filter_type='Bandpass',
        freq_min= 0.25,
        freq_max= 0.667,
        pick_type='from_fk_database',
        fk_database=path_greens,
        window_type='cap_bw',
        window_length=15.,
        padding_length=2.,
        weight_type='cap_bw',
        weight_file=path_weights,
        )

    process_sw = process_data(
        filter_type='Bandpass',
        freq_min=0.025,
        freq_max=0.0625,
        pick_type='from_fk_database',
        fk_database=path_greens,
        window_type='cap_sw',
        window_length=150.,
        padding_length=10.,
        weight_type='cap_sw',
        weight_file=path_weights,
        )

    process_data = {
       'body_waves': process_bw,
       'surface_waves': process_sw,
       }

"""


MisfitComments="""
    #
    # We define misfit as a sum of indepedent body- and surface-wave 
    # contributions
    #
"""


MisfitDefinitions="""
    misfit_bw = misfit(
        time_shift_max=2.,
        time_shift_groups=['ZR'],
        )

    misfit_sw = misfit(
        time_shift_max=10.,
        time_shift_groups=['ZR','T'],
        )

    misfit = {
        'body_waves': misfit_bw,
        'surface_waves': misfit_sw,
        }

"""


GridDC3="""
    #
    # Here we specify the source parameter grid
    #

    grid = DCGridRandom(
        npts=50000,
        Mw=4.5)

    rise_time = trapezoid_rise_time(Mw=4.5)
    wavelet = Trapezoid(rise_time)


"""


GridDC5="""
    #
    # Here we specify the source parameter grid
    #

    grid = DCGridRandom(
        npts=50000,
        Mw=4.5)

    origins = OriginGrid(depth=np.arange(2500.,20000.,2500.),
        latitude=origin.latitude,
        longitude=origin.longitude)

    rise_time = trapezoid_rise_time(Mw=4.5)
    wavelet = Trapezoid(rise_time)

"""


GridFMT5="""
    #
    # Here we specify the source parameter grid
    #

    grid = MTGridRandom(
        npts=1000000,
        Mw=4.5)

    rise_time = trapezoid_rise_time(Mw=4.5)
    wavelet = Trapezoid(rise_time)

"""


GridBenchmarkCAPFK="""
    #
    # Here we specify the source parameter grid
    #
    from mtuq.grid_search import callback
    from mtuq.util.grid import UnstructuredGrid
    from mtuq.util.moment_tensor import tape2015

    Mw = 4.3
    #M0 = 10.**(1.5*4.3 + 16.1)
    M0 = 1.

    # explosion source
    rho0 = np.sqrt(2.)*M0
    v0 = 0.
    w0 = 1.1780972450961724
    kappa0 = 90.
    sigma0 = 90.
    h0 = 0.

    # double-couple source #1
    rho1 = np.sqrt(2.)*M0
    v1 = 0.
    w1 = 0.
    kappa1 = 180.
    sigma1 = 0.
    h1 = 0.5

    # double-couple source #2
    rho2 = np.sqrt(2.)*M0
    v2 = 0.
    w2 = 0.
    kappa2 = 180.
    sigma2 = 0.
    h2 = 0.5

    grid =  UnstructuredGrid({
        'rho': np.array([rho0, rho1, rho2]),
        'v': np.array([v0, v1, v2]),
        'w': np.array([w0, w1, w2]),
        'kappa': np.array([kappa0, kappa1, kappa2]),
        'sigma': np.array([sigma0, sigma1, sigma2]),
        'h': np.array([h0, h1, h2])},
        callback=callback)

    rise_time = trapezoid_rise_time(Mw=4.3)
    wavelet = Trapezoid(rise_time)

"""



GridSearchSerial="""
    #
    # The main I/O work starts now
    #

    print 'Reading data...\\n'
    data = mtuq.dataset.sac.reader(path_data, wildcard='*.[zrt]')
    data.sort_by_distance()

    stations  = []
    for stream in data:
        stations += [stream.station]
    origin = data.get_origin()


    print 'Processing data...\\n'
    processed_data = {}
    for key in ['body_waves', 'surface_waves']:
        processed_data[key] = data.map(process_data[key])
    data = processed_data


    print 'Reading Greens functions...\\n'
    factory = mtuq.greens_tensor.fk.GreensTensorFactory(path_greens)
    greens = factory(stations, origin)


    print 'Processing Greens functions...\\n'
    greens.convolve(wavelet)
    processed_greens = {}
    for key in ['body_waves', 'surface_waves']:
        processed_greens[key] = greens.map(process_data[key])
    greens = processed_greens


    #
    # The main computational work starts nows
    #

    print 'Carrying out grid search...\\n'
    results = grid_search_serial(data, greens, misfit, grid)


    print 'Saving results...\\n'
    #grid.save(event_name+'.h5', {'misfit': results})
    best_mt = grid.get(results.argmin())


    print 'Plotting waveforms...\\n'
    synthetics = {}
    for key in ['body_waves', 'surface_waves']:
        synthetics[key] = greens[key].get_synthetics(best_mt)
    plot_waveforms(event_name+'.png', data, synthetics, misfit)


"""



GridSearchMPI="""
    from mpi4py import MPI
    comm = MPI.COMM_WORLD


    #
    # The main I/O work starts now
    #

    if comm.rank==0:
        print 'Reading data...\\n'
        data = mtuq.dataset.sac.reader(path_data, wildcard='*.[zrt]')
        data.sort_by_distance()

        stations  = []
        for stream in data:
            stations += [stream.station]
        origin = data.get_origin()

        print 'Processing data...\\n'
        processed_data = {}
        for key in ['body_waves', 'surface_waves']:
            processed_data[key] = data.map(process_data[key])
        data = processed_data

        print 'Reading Greens functions...\\n'
        factory = mtuq.greens_tensor.fk.GreensTensorFactory(path_greens)
        greens = factory(stations, origin)

        print 'Processing Greens functions...\\n'
        greens.convolve(wavelet)
        processed_greens = {}
        for key in ['body_waves', 'surface_waves']:
            processed_greens[key] = greens.map(process_data[key])
        greens = processed_greens

    else:
        data = None
        greens = None

    data = comm.bcast(data, root=0)
    greens = comm.bcast(greens, root=0)


    #
    # The main computational work starts now
    #

    if comm.rank==0:
        print 'Carrying out grid search...\\n'
    results = grid_search_mpi(data, greens, misfit, grid)
    results = comm.gather(results, root=0)


    if comm.rank==0:
        print 'Saving results...\\n'
        results = np.concatenate(results)
        grid.save(event_name+'.h5', {'misfit': results})
        best_mt = grid.get(results.argmin())


    if comm.rank==0:
        print 'Plotting waveforms...\\n'
        synthetics = {}
        for key in ['body_waves', 'surface_waves']:
            synthetics[key] = greens[key].get_synthetics(best_mt)
        plot_waveforms(event_name+'.png', data, synthetics, misfit)


"""



GridSearchMPI2="""
    #
    # The main work of the grid search starts now
    #
    from mpi4py import MPI
    comm = MPI.COMM_WORLD


    if comm.rank==0:
        print 'Reading data...\\n'
        data = mtuq.dataset.sac.reader(path_data, wildcard='*.[zrt]')
        data.sort_by_distance()

        stations  = []
        for stream in data:
            stations += [stream.station]
        origin = data.get_origin()

        print 'Processing data...\\n'
        processed_data = {}
        for key in ['body_waves', 'surface_waves']:
            processed_data[key] = data.map(process_data[key])
        data = processed_data
    else:
        data = None

    data = comm.bcast(data, root=0)


   for origin, magnitude in cross(origins, magnitudes):
        if comm.rank==0:
            print 'Reading Greens functions...\\n'
            factory = mtuq.greens_tensor.fk.GreensTensorFactory(path_greens)
            greens = factory(stations, origin)

            print 'Processing Greens functions...\\n'
            rise_time = trapezoid_rise_time(magnitude)
            wavelet = Trapezoid(rise_time)
            greens.convolve(wavelet)

            processed_greens = {}
            for key in ['body_waves', 'surface_waves']:
                processed_greens[key] = greens.map(process_data[key])
            greens = processed_greens

        else:
            greens = None

        greens = comm.bcast(greens, root=0)


        if comm.rank==0:
            print 'Carrying out grid search...\\n'
        results = grid_search_mpi(data, greens, misfit, grid)
        results = comm.gather(results, root=0)


        if comm.rank==0:
            print 'Saving results...\\n'
            results = np.concatenate(results)
            grid.save(event_name+'.h5', {'misfit': results})


        if comm.rank==0:
            print 'Plotting waveforms...\\n'
            synthetics = {}
            for key in ['body_waves', 'surface_waves']:
                synthetics[key] = greens[key].get_synthetics(best_mt)
            plot_waveforms(event_name+'.png', data, synthetics, misfit)


"""


RunBenchmarkCAPFK="""
    #
    # The benchmark starts now
    #

    print 'Reading data...\\n'
    data = mtuq.dataset.sac.reader(path_data, wildcard='*.[zrt]')
    data.sort_by_distance()

    stations  = []
    for stream in data:
        stations += [stream.station]
    origin = data.get_origin()


    print 'Processing data...\\n'
    processed_data = {}
    for key in ['body_waves', 'surface_waves']:
        processed_data[key] = data.map(process_data[key])
    data = processed_data


    print 'Reading Greens functions...\\n'
    factory = mtuq.greens_tensor.fk.GreensTensorFactory(path_greens)
    greens = factory(stations, origin)

    print 'Processing Greens functions...\\n'
    greens.convolve(wavelet)
    processed_greens = {}
    for key in ['body_waves', 'surface_waves']:
        processed_greens[key] = greens.map(process_data[key])
    greens = processed_greens

    print 'Plotting waveforms...\\n'
    from copy import deepcopy
    from mtuq.util.cap_util import get_synthetics_cap, get_synthetics_mtuq

    paths = [
        '/home/rmodrak/packages/capuaf/OUTPUT_DIR0',
        '/home/rmodrak/packages/capuaf/OUTPUT_DIR1',
        '/home/rmodrak/packages/capuaf/OUTPUT_DIR2',
        ]

    for _i, mt in enumerate(grid):
        synthetics_mtuq = get_synthetics_mtuq(greens, mt)
        synthetics_cap = get_synthetics_cap(deepcopy(data), paths[_i])
        filename = 'cap_fk_'+str(_i)+'.png'
        plot_waveforms(filename, synthetics_cap, synthetics_mtuq, misfit)

"""



if __name__=='__main__':
    import os
    import re

    from mtuq.util.util import root
    os.chdir(root())


    with open('examples/GridSearch.DoubleCouple3.py', 'w') as file:
        file.write(Imports)
        file.write(DocstringDC3)
        file.write(PathsComments)
        file.write(PathsDefinitions)
        file.write(DataProcessingComments)
        file.write(DataProcessingDefinitions)
        file.write(MisfitComments)
        file.write(MisfitDefinitions)
        file.write(GridDC3)
        file.write(GridSearchMPI)


    with open('examples/GridSearch.DoubleCouple5.py', 'w') as file:
        file.write(Imports)
        file.write(DocstringDC5)
        file.write(PathsComments)
        file.write(PathsDefinitions)
        file.write(DataProcessingComments)
        file.write(DataProcessingDefinitions)
        file.write(MisfitDefinitions)
        file.write(GridDC5)
        file.write(GridSearchMPI2)


    with open('examples/GridSearch.FullMomentTensor5.py', 'w') as file:
        file.write(Imports)
        file.write(DocstringFMT5)
        file.write(PathsDefinitions)
        file.write(DataProcessingComments)
        file.write(DataProcessingDefinitions)
        file.write(MisfitComments)
        file.write(MisfitDefinitions)
        file.write(GridFMT5)
        file.write(GridSearchMPI)


    with open('examples/GridSearch.DoubleCouple3.Serial.py', 'w') as file:
        file.write(
            re.sub(
            'grid_search_mpi',
            'grid_search_serial',
            Imports))
        file.write(DocstringDC3Serial)
        file.write(PathsComments)
        file.write(PathsDefinitions)
        file.write(DataProcessingComments)
        file.write(DataProcessingDefinitions)
        file.write(MisfitComments)
        file.write(MisfitDefinitions)
        file.write(GridDC3)
        file.write(GridSearchSerial)


    with open('tests/integration_grid_search.py', 'w') as file:
        file.write(
            re.sub(
            'grid_search_mpi',
            'grid_search_serial',
            Imports))
        file.write(DocstringIntegrationTest)
        file.write(PathsDefinitions)
        file.write(DataProcessingDefinitions)
        file.write(MisfitDefinitions)
        file.write(GridDC3)
        file.write(GridSearchSerial)


    with open('tests/benchmark_cap_fk.py', 'w') as file:
        file.write(
            re.sub(
            'grid_search_mpi',
            'grid_search_serial',
            Imports))
        file.write(DocstringBenchmarkCAPFK)
        file.write(PathsDefinitions)
        file.write(
            re.sub(
            'padding_length=.*',
            'padding_length=0,',
            DataProcessingDefinitions))
        file.write(
            re.sub(
            'time_shift_max=.*',
            'time_shift_max=0.,',
            MisfitDefinitions))
        file.write(GridBenchmarkCAPFK)
        file.write(RunBenchmarkCAPFK)








